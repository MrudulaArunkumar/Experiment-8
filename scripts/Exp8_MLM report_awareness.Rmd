---
title: "Exp8_MLM report"
author: "Mrudula & Carina"
date: "`r format(Sys.time(), '%d %B,%Y')`"
output:
  html_document:
    theme: readable
    highlight: breezedark
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 7
    fig_height: 4
    code_folding: hide
---

**This report highlights the results from the Multi level analysis for Experiment 8 and only for participants with awareness.**
Data from experiment 8 has already been prepared with the relevant factors such as :

1. Distance: How far ago was the last occurence 

2. Distance_type: Was the last occurence a SingleD or a MultipleD trial. If it is MultipleD then Distance_type is 1 and if it is SingleD then it is 2

3. ResponseRel: Whether the previous response was repeated or changed.

4. Validity and Saliency factors were converted to numeric: Valid trials are 1, and invalid and -1 similarly Salient is 1 and nonsalient is -1

5. Only the RTs of SingleD trials were used for analysis

The prepared dataset is saved as  *Exp8_withawareness.csv* and is loaded to perform the MLM.

```{r loadlibsdata, echo=FALSE, message=FALSE, warning=FALSE}

#loading important libraries
library(plyr)
library(lme4)
library(tidyverse)
library(here)
library(lmerTest)
library(ggplot2)
library(sjPlot)
library(rmarkdown)
library(knitr)
library(pander)


raw.data<-read.csv(here("Data","Exp8_withawareness.csv"))
raw.data <- raw.data %>% select(-X)

```

### Data Preparation and cleaning

This data is further edited to be prepared for analysis in the following ways

1. Create numeric factor for Previous Response : RR (1) and RC(2)

2. Removing compound trials and choosing only SingleD trials that were used for analysis

3. Centering predictors : within participants as level 1 predictors are participants. This is done using the formula $cwp = Actual value - mean$

    * Previous Response_cwp
    
    * Distance_cwp
    
    * Distance_Type_cwp

These are then merged with the main dataframe
    

```{r dataprep,include=FALSE, warning=FALSE, message=FALSE }

#create numerical var for response relation

raw.data$previous_rm<-ifelse(raw.data$ResponseRel=="RR", 1, 2)
table(raw.data$ResponseRel, raw.data$previous_rm)


#limit analyses to testtrials only ####
#table(raw.data$Condition)
raw.data<-subset(raw.data, subset = (raw.data$Condition=="SingleD"))


#center predictors####
#factors validity and saliency contrast coded with -1/1 as levels
summary(raw.data$val)
summary(raw.data$sal)


#centering within person (recommended, since hypotheses focus on level 1 predictors####

summary(raw.data$previous_rm)
summary(raw.data$Distance)
summary(raw.data$Distance_type) # 1 indicates MultipleD and 2 indicates SingleD
  
  #previous_rm
  means.previous_rm <- aggregate(data = raw.data, previous_rm ~ participant, mean)
  names(means.previous_rm)[2]<-"previous_rm_mean"
  
  raw.data<-merge (raw.data, means.previous_rm, by="participant")
  
  raw.data$previous_rm_cwp <- raw.data$previous_rm-raw.data$previous_rm_mean
  summary(raw.data$previous_rm_cwp)
  
  #check whether person mean centering was correctly done
  all(raw.data$previous_rm == raw.data$previous_rm_cwp+raw.data$previous_rm_mean)


  #Distance
  means.Distance<- aggregate(data = raw.data, Distance ~ participant, mean)
  names(means.Distance)[2]<-"Distance_mean"
  
  raw.data<-merge (raw.data, means.Distance, by="participant")
  
  raw.data$Distance_cwp <- raw.data$Distance-raw.data$Distance_mean
  summary(raw.data$Distance_cwp)
  
  #check whether person mean centering was correctly done
  all(raw.data$Distance == raw.data$Distance_cwp+raw.data$Distance_mean)
  

  #Distance type
  
  means.Distance_type<- aggregate(data = raw.data, Distance_type ~ participant, mean)
  names(means.Distance_type)[2]<-"Distance_type_mean"
  
  raw.data<-merge (raw.data, means.Distance_type, by="participant")
  
  raw.data$Distance_type_cwp <- raw.data$Distance_type-raw.data$Distance_type_mean
  summary(raw.data$Distance_type_cwp)
  
  #check whether person mean centering was correctly done
  all(raw.data$Distance_type == raw.data$Distance_type_cwp+raw.data$Distance_type_mean)

  raw.data <- raw.data %>%
    select(previous_rm_cwp,previous_rm_mean,Distance_cwp,Distance_mean,Distance_type_cwp,Distance_type_mean,everything())
#new var for errors
  raw.data$err_trials <-1-raw.data$ACC_trials
  
```


# Multi Level Analysis #

## 1. Model 1 - similar to ANOVA data

This model replicates the ANOVa on the aggregated data used in the standard analysis. The factors used are:

 - Validity: valid (1) and invalid(-1)
 - Saliency: Salient(1) and nonsalient(-1)
 - Val*Sal interaction: indicating overshadowing if validity effect is larger for salient vs nonsalient trials
 
```{r datMLM, include=FALSE, message=FALSE, warning=FALSE}

dat<-raw.data[,c("participant", "RT_io","val", "sal", "previous_rm", "Distance", "Distance_type")]    
  
#write.table(dat, file="dat.dat", col.names=F, row.names=F, na="-999", dec=".", sep="\t")  
paste(names(dat), collapse = " ")
head(dat)

```
 
### 1. with RTs as dependant variable

```{r m1RT, warning=FALSE,message=FALSE}
randomSlopes_m1<-lmer(RT_io~1+val*sal + (1+val*sal|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")


tab_model(randomSlopes_m1, show.se = TRUE,show.stat = TRUE, show.ci = FALSE,show.aic = TRUE, show.loglik = TRUE, 
                  dv.labels = "Reaction Time")

plot_model(randomSlopes_m1, type = "pred", terms = c("sal", "val[minmax]"))


summary(randomSlopes_m1)
```

### 2. with ErrorRates

The model with all predictors as random effects is a better fit

```{r m1er, warning=FALSE, message=FALSE}

#Error rates

randomSlopes_m1_err<-glmer(err_trials~1+val*sal + (1+val*sal|participant), 
                      data=raw.data, 
                      na.action = "na.omit", binomial)


summary(randomSlopes_m1_err)

tab_model(randomSlopes_m1_err, show.se = TRUE,show.stat = TRUE, show.ci = FALSE,show.aic = TRUE, show.loglik = TRUE, 
                  dv.labels = "Error Rate")
# significant interaction and significant main effect of saliency for both types of randomslopes 

plot_model(randomSlopes_m1_err, type = "pred", terms = c("sal", "val[minmax]"))
```

## 2. Model2 : Adding Previous Response and Distance  as factors

Will the interaction still survive upon adding these factors? It *almost* does for RT, infact becomes stronger upon adding the binding factors.
and strongly does for ER

### 1. with RT

```{r m2RT, warning=FALSE, message=FALSE}
randomSlopes_m2<-lmer(RT_io~1+val*sal + previous_rm_cwp+ Distance_cwp +(1+val*sal + previous_rm_cwp + Distance_cwp|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")
tab_model(randomSlopes_m1, randomSlopes_m2, show.se = TRUE,show.stat = TRUE, show.ci = FALSE, show.aic = TRUE, show.loglik = TRUE,
                  dv.labels = "Reaction Time")
summary(randomSlopes_m2)
```

### 2. With ER

```{r m2ER, warning=FALSE, message=FALSE}
randomSlopes_m2_err<-glmer(err_trials~1+val*sal + previous_rm_cwp+ Distance_cwp + (1+val*sal + previous_rm_cwp + Distance_cwp|participant), 
                      data=raw.data, 
                      binomial,
                      na.action = "na.omit")
# 
# randomSlopes_m2b_err<-glmer(err_trials~1+val*sal + previous_rm_cwp+ Distance_cwp + Distance_type_cwp +(1|participant), 
#                       data=raw.data, 
#                       binomial,
#                       na.action = "na.omit")
tab_model(randomSlopes_m2_err,randomSlopes_m1_err, show.ci = FALSE, show.p = TRUE, show.stat = TRUE, show.aic = TRUE, show.loglik = TRUE)
summary(randomSlopes_m2_err)
# summary(randomSlopes_m2b_err)

```



## 3. Model3 : Adding the level 2 interaction factors

### with RT

The ValxSal interaction is *almost* significant in RTs and significant in ER. There is a main effect of Previous Response in RTs but not in the ER

```{r m4, warning=FALSE, message=FALSE}
randomSlopes_m3<-lmer(RT_io~1+val*sal*previous_rm_cwp*Distance_cwp+(1+val*sal*previous_rm_cwp*Distance_cwp|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")
tab_model(randomSlopes_m3, show.ci = FALSE, show.stat = TRUE, show.aic = TRUE, show.loglik = TRUE)
summary(randomSlopes_m3)
```

### with ER

```{r m4er, warning=FALSE, message=FALSE}

randomSlopes_m3_err<-lmer(err_trials~1+val*sal*previous_rm_cwp*Distance_cwp+(1+val*sal*previous_rm_cwp*Distance_cwp|participant), 
                      data=raw.data, 
                      REML=F,
                      na.action = "na.omit")


tab_model(randomSlopes_m3_err, show.ci = FALSE, show.stat = TRUE, show.aic = TRUE, show.loglik = TRUE)

summary(randomSlopes_m3_err)
#RT: val *sal Interaction borderline significant at p = 0.054, t value = 1.9 and PRevious response is significant at 0.03 with tvalue of 2.2
#Err: val *sal Interaction still significant, in addition, Saliency main effect and borderline validity t = 1.7
```

Summary of model 2 and model 4

```{r m2m4rter, warning=FALSE, message=FALSE}
tab_model(randomSlopes_m2,randomSlopes_m2_err,randomSlopes_m3,randomSlopes_m3_err, show.ci = FALSE, show.stat = TRUE, show.aic = TRUE, show.loglik = TRUE)
```

## 4. Intercept Model

### 1. with RT

```{r m0RT, warning=FALSE, message=FALSE}
randomIntercept_m0<-lmer(RT_io~1 + (1|participant), 
                         data=raw.data, 
                         REML=F,
                         na.action = "na.omit")
tab_model(randomIntercept_m0, show.ci = FALSE, show.stat = FALSE, show.aic = TRUE, show.aicc = TRUE, show.loglik = TRUE)
summary(randomIntercept_m0)

```

### 2. With ER

```{r m0ER, warning=FALSE, message=FALSE}
randomIntercept_m0_err<-lmer(err_trials~1 + (1|participant), 
                         data=raw.data, 
                         REML=F,
                         na.action = "na.omit")
tab_model(randomIntercept_m0_err, show.ci = FALSE, show.stat = FALSE, show.aic = TRUE, show.aicc = TRUE, show.loglik = TRUE)
summary(randomIntercept_m0_err)
```


## Model Comparisons

### 1. Model 1 vs intercept

Model 1 offers a better fit for the RT data
```{r}
pander(anova(randomIntercept_m0, randomSlopes_m1), style = "rmarkdown",caption = "Model 1 vs Intercept, for RTs")
pander(anova(randomIntercept_m0_err, randomSlopes_m1_err), style = "rmarkdown", caption = "Model1 vs Intercept, for ER")
tab_model(randomIntercept_m0,randomSlopes_m1, show.ci = FALSE, show.stat = TRUE,show.aic = TRUE, show.aicc = TRUE)
```

### Model 1 vs Model 2

Comparing Models with only Validity and Saliency (Model 1) vs one where the binding factors of previous response and Distance (Model 2) are introduced. 

#### RT
> Model 2 offers a better fit for the data

```{r m1m2, warning=FALSE, message=FALSE}
pander(anova(randomSlopes_m1, randomSlopes_m2), style = "rmarkdown",caption = "Model 1 vs Model 2, for RTs")
```

#### ER

```{r m1m2err, warning=FALSE,message=FALSE}
pander(anova(randomSlopes_m1_err, randomSlopes_m2_err), style = "rmarkdown", caption = "Model1 vs Model2, for ER")

```

### Model 1 vs Model 3

Comparing standard model with model 3 that has the interaction terms of the binding data as well

> Model 4 fits better than Model 1

```{r m1m4, warning=FALSE, message=FALSE}
pander(anova(randomSlopes_m1, randomSlopes_m3), style = "rmarkdown", caption = "Model 1 vs Model 4, RT")
pander(anova(randomSlopes_m1_err, randomSlopes_m3_err), style = "rmarkdown", caption = "Model 1 vs Model 3, RT")
```

### Model 2 vs Model 3

They do not significantly differ.

```{r m2m4, warning=FALSE, message=FALSE}

pander(anova(randomSlopes_m3, randomSlopes_m2), style = "rmarkdown", caption = "Model 2 vs Model 3, RT")

```
