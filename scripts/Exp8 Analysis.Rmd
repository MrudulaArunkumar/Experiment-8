---
title: "Exp8 Analysis"
author: "Mrudula Arunkumar"
date: "`r format(Sys.time(), '%d %B,%Y')`"
output:
  html_document:
    theme: readable
    highlight: breezedark
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 7
    fig_height: 4
    code_folding: hide
  pdf_document:
    toc: yes
---

**This document contains the result memo of Experiment 8 aimed to disentangle the awareness/insight factor and the retrieval effects. We found from out previous experiment *Exp7 Analysis.rmd* that overshadowing was present but this seemed to be driven by the nudges that participants received as those with awareness showed the effect. While looking at it from an SRB level and previous occurence, it did not moderate the interaction. But this is also tricky because the design of the previous experiment had test and learn trials intermixed that also visually looked different. So with this experiment, it builds on from the success of overshadowing in the last experiment by using only learn-like displays but testing overshadowing by manipulating the presence/absence of the salient or nonsalient distractor, similar to how it looked in the guessing learn trials of the previous experiment. So this will use the terms "MultipleD" to indicate the compound learn trials display and "SingleD" to mark the ones where one of the distractors is present. There will also be no guessing trials in between, and participants will only be asked at the end of the experiment. Given that they all look similar this experiment work can disentangle the role of inisght and provide more scope to explore retrieval effects.**

```{r loadlibs, include=FALSE, message=FALSE}

library(tidyverse)
library(plyr)
library(ez)
library(schoRsch)
library(knitr)
library(pander)
library(rmarkdown)
library(reshape2)
library(here)
library(ggpubr)
library(lme4)
library(nlme)
library(lmerTest)

#set_here()

Exp8data <- read.csv(here("Data", "Exp8_fulldataset.csv"))
Exp8data$participant <- as.factor(Exp8data$participant)
#Exp8data <- Exp8data%>%group_by(participant)%>%fill(participant,.direction = "up")
#table(Exp8data$participant)
##exploratory removing participants with average performance
`%notin%` <- Negate(`%in%`)

```

Below is the overview of the experiment trials.

```{r image, echo=FALSE, out.width="100%", fig.align = 'center'}
knitr::include_graphics(here("Figures","Trial Count.png"))
knitr::include_graphics(here("Figures","Experiment flow.png"))
```

The trials are divided as SingleDistractor (SingleD) and MultipleDistractor (MultipleD). SingleD is where either the **salient** or the **nonsalient** distractor is presented along with a *random* letter chosen as the other distractor. MultipleD is the compound display where participants learn the association for **both salient and nonsalient** letters.

1. The MultipleD trials with both nonsalient and salient letters: for 'left' and 'right' responses

```{r trials, echo=FALSE, out.width="49%", fig.show = "hold"}

knitr::include_graphics(here("Figures","GX learn.png"))
knitr::include_graphics(here("Figures","VL learn.png"))

```

2. Salient SingleD trials

```{r salsingled, echo = FALSE,out.width='49%', fig.show='hold'}

knitr::include_graphics(here("Figures","G salient.png"))
knitr::include_graphics(here("Figures","V salient.png"))
```

3. NonSalient SingleD trials

```{r nsalsingled, echo=FALSE, out.width='49%', fig.show='hold'}

knitr::include_graphics(here("Figures","X nonsalient.png"))
knitr::include_graphics(here("Figures","L nonsalient.png"))
```


# Data preparation and cleaning
-   Removing unnecessary columns generated by psychopy
-   Preparing the RT trial, by eliminating the square brackets and splitting it in cases where two keys were registered.
-   Creating a column for Accuracy and Error Rate
-   adding a Bonus column that computes the points received by each participant

> 3 participants had to be removed due to high Error Rate, so N = 67 instead of 70. 

```{r cleaning, include=FALSE, message=FALSE, warning=FALSE}
#removing unnecessary columns
Exp8data <- Exp8data %>%
  select(-X,-ConsentKey.keys,-ConsentKey.rt,-Begin.keys,-Begin.rt,-checkresp.corr,-checkresp.keys,-checkresp.rt,-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisN,-Attention.thisIndex,-Attention.ran,-AttnQuestion,-AttnAnswer,-NextStep.keys,-NextStep.rt,-InstRep.ran,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,-InstRep.thisIndex,-PracProceed.keys,-PracProceed.rt,-Prac_loop.thisRepN,-Prac_loop.thisTrialN,-Prac_loop.thisN,-Prac_loop.thisIndex,-Prac_loop.ran,-Exp_proceed.keys,-Exp_proceed.rt,-PracRepeat.ran,-PracRepeat.thisRepN,-PracRepeat.thisN,-PracRepeat.thisIndex,-PracRepeat.thisTrialN,-brkContinue.keys,-PauseResp.keys,-PauseResp.rt, -CA_Proceed.keys,-CA_Proceed.rt,-headstartLearn.thisRepN,-headstartLearn.thisTrialN,-headstartLearn.thisIndex,-headstartLearn.thisN,-headstartLearn.ran,-ExpTrials.ran,-ExpTrials.thisIndex,-CA_trials.thisRepN,-CA_trials.thisN,-CA_trials.thisIndex,-CA_trials.thisTrialN,-CA_trials.ran,-AwareQ_loop.thisRepN,-AwareQ_loop.ran,-AwareQ_loop.thisIndex,-AwareQ_loop.thisTrialN,-todebrief.keys,-Finalend.keys)

Exp8data <- Exp8data %>%
  mutate(BlockCount = ifelse(ExpTrials.thisN <= 104, 1,
                             ifelse(ExpTrials.thisN <=208 & ExpTrials.thisN > 104,2,
                                    ifelse(ExpTrials.thisN <= 312 & ExpTrials.thisN > 208,3,
                                           ifelse(ExpTrials.thisN <= 415 & ExpTrials.thisN > 312,4,NA)))))


#adjusting RT
Exp8data <- separate(Exp8data, col = TargetResp.rt, into = c("RT_Trials", "RT_secondary"), sep = ',')
Exp8data$RT_Trials <- Exp8data$RT_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp8data$RT_Trials)
Exp8data$RT_Trials <- 1000*(Exp8data$RT_Trials)


#creating a Bonus column, for prolific
Exp8data$Bonus <- as.integer(Exp8data$Bonus)

#creating an aggegrate File with bonus
Exp8Bonus <- aggregate(data = Exp8data, Bonus~PROLIFIC_ID, sum)
Exp8Bonus$Perf <- na.omit(Exp8data$Performance)


###creating a separate df with the contingency awareness
Exp8_CA <- Exp8data%>%
 filter(Target == "?" | str_detect(AwareQ, "Press"))




Exp8data <- Exp8data%>%drop_na(RT_Trials)
#table(Exp8data$participant)
#combining accuracy from first block and main block
Exp8data$ACC_trials <- Exp8data$TargetResp.corr



Exp8data$ErrorRate <- 1 - Exp8data$ACC_trials
Exp8ER <- aggregate(data = Exp8data,ErrorRate~PROLIFIC_ID,mean)
Exp8RT <- aggregate(data = Exp8data,RT_Trials~PROLIFIC_ID,mean)

#filter erroneous participants
Exp8data <- Exp8data %>%
  filter(participant %notin% c(20,70,12))
```

## Descriptives

Summary of the overall Reaction Time, accuracy and Error Rate

```{r descriptives, echo=FALSE,results='asis'}

pander(summary(Exp8data$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp8data$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

pander(round(table(Exp8data$ACC_trials)/nrow(Exp8data)*100, digits = 3), style = 'rmarkdown', caption = "Percentage of errors")
```

Upon implementing the exclusion criteria

-   Outliers (1.5x above third quartile) --\> used for the analysis
-   Farouts (3x)above third quartile)
-   very Fast RTs, less than 200ms

```{r exclusions, echo=FALSE, results='asis'}
Exp8data$RT_Trials[Exp8data$ACC_trials==0] <- NA



#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp8data <- ddply(Exp8data, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp8data$RT_ifo <- Exp8data$RT_Trials
Exp8data$RT_io <- Exp8data$RT_Trials

Exp8data$RT_ifo[Exp8data$RT_ifo > Exp8data$Farouts|Exp8data$RT_ifo < 200] <- NA

Exp8data$RT_io[Exp8data$RT_io > Exp8data$Outlier|Exp8data$RT_io < 200] <- NA


pander(summary(Exp8data$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp8data$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")

```

# ANALYSES


## 1. Validity Manipulation check - all trials

> There is no validity effect seen in RTs. $t = 1.4, p = .16$

```{r valcheck, echo=FALSE,message=FALSE,results='asis'}
##creating an aggregate to check for validity effect
#Exp8multiple_agg <- aggregate(data = Exp8data, RT_ifo~participant+Validity,mean)

Exp8multiple_agg_o <- aggregate(data = Exp8data, RT_io~participant+Validity,mean)
#sum(is.na(Exp8data$RT_io))

#for farouts
#pander(aggregate(data = Exp8multiple_agg, RT_ifo~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, farouts excluded")

#pander((t.test(data = Exp8multiple_agg, RT_ifo~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials")



#for outliers
pander(aggregate(data = Exp8multiple_agg_o, RT_io~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, outliers excluded")


pander((t.test(data = Exp8multiple_agg_o, RT_io~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials-excluding outliers")

valmain <- ggplot(Exp8multiple_agg_o, aes(x=Validity, y=RT_io,color = Validity))+
    geom_line(aes(group = 1),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Validity, shape = Validity),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(500,600))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean of valid and invalid trials")
valmain
#ggsave(filename = here("Figures","Validity_main.png"),valmain)
```

## 2. Saliency Manipulation Check

This analysis checks whether the saliency manipulation worked by comparing the RT between trials where the number appeared in salient letters position vs non salient letter's position.

> There is no significant difference between trials where the target appeared at the salient letter position vs non salient letter's position ($p = 0.12$), with the salient letter being 15ms faster than nonsalient letter's position.

*It was significant at N = 65, upon entire data calculation it is not significant*

```{r salcheck, echo=FALSE, message=FALSE,results='asis'}
# Exp8SalCheck <- aggregate(data = Exp8data, RT_ifo~participant+Saliency, subset = (Block == "SalMC"), mean)
Exp8SalCheck_o <- aggregate(data = Exp8data, RT_io~participant+Saliency, subset = (Block == "SalMC"), mean)

# 
# pander(t.test(RT_ifo~Saliency, data = Exp8SalCheck,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation")

pander(t.test(RT_io~Saliency, data = Exp8SalCheck_o,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation, outliers")

salmain <- ggplot(Exp8SalCheck_o, aes(x=Saliency, y=RT_io,color = Saliency))+
    geom_line(aes(group = 1),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Saliency, shape = Saliency),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(600,700))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean of trial with target behind salient vs non salient distractor")
salmain

#ggsave(filename = here("Figures","Saliency_main.png"),salmain)
```

## 3. Interaction of Validity x Saliency in test trials

This analysis is the main one concerning overshadowing.

1.  Farouts: Not analyzed further as outliers prove to be a better exclusion criteria

```{r interactionfo, eval=FALSE, warning=FALSE, message=FALSE}

## aggregating the data for farouts and for outliers

Exp8agg_fo <- aggregate(data = Exp8data, RT_ifo~participant+Validity+Saliency, subset = (Condition == "SingleD"), mean)


anova_VS_fo <- ezANOVA(data = Exp8agg_fo,
                       dv = RT_ifo,
                       wid = participant,
                       within = .(Validity, Saliency),type = 3,
                       detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VS_fo, style = "rmarkdown", caption = "ANOVA for test trials with Validity and Saliency as factors",split.table = Inf, missing = NA)

# aov_VS_fo <- aov(RT_ifo~(Validity*Saliency)+Error(participant/(Validity*Saliency)), data = Exp8agg_fo)
# summary(aov_VS_fo)

ezPlot(data = Exp8agg_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity, Saliency),
       split = Validity, x = Saliency, do_bars = FALSE)+theme_classic()+
  ggtitle("Interaction effect between saliency and validity for test trials")



#stdInteraction_fo <- ggplot(Exp8agg_fo, aes(x=Saliency, y=RT_ifo,color = Validity))+
#    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
#    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+ylim(500,600)+
#  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
#  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")

#ggsave(filename = here("Figures","interaction_fo.png"),stdInteraction_fo)

mean_valEffect_fo <- ezStats(data = Exp8agg_fo,
        dv = RT_ifo,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)

pander(mean_valEffect_fo, style = "rmarkdown", title = "Validity effect(invalid-valid) for salient and non salient letters in test trials(farouts)")


pander(t.test(data = Exp8agg_fo, RT_ifo~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, farouts")
```

2.  Outliers:

The validity effect is not significant, $F = 0.01, p = 0.63$, however the main effect of saliency is *almost* significant at $ p = 0.053$. The interaction between validity and saliency is also *almost* significant with $F = 3.28, p = .074$. One thing to note in this scenario is that the total number of valid and invalid trials has a 90:10 contingency ratio, which leads to less data points for invalid trials and all the more likely to miss more since invalid trials are more error-prone leading to NA RTs.

```{r interactiono, warning=FALSE, message=FALSE, results='asis'}
##for outliers
  
Exp8agg_o <- aggregate(data = Exp8data, RT_io~participant+Validity+Saliency, subset = (Condition == "SingleD"), mean)

#ANOVA
anova_VS_o <- ezANOVA(data = Exp8agg_o,
                       dv = RT_io,
                       wid = participant,
                       within = .(Validity, Saliency),
                       detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VS_o, style = "rmarkdown", title = "ANOVA for test trials(w/o outliers) with Validity and Saliency as factors",split.table = Inf, missing = NA)



stdInteraction_o <- ggplot(Exp8agg_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")
stdInteraction_o
#ggsave(filename = here("Figures","interaction_o.png"),stdInteraction_o,width = 6,height = 4)

```

Here is a closer look at the effects, showing the mean difference between valid and invalid in each condition. The effects are not significant for both the salient and nonsalient trials.

```{r meandiff, echo = FALSE, warning=FALSE, message=FALSE, results='asis'}

#Mean difference
mean_valEffect_o <- ezStats(data = Exp8agg_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)


pander(mean_valEffect_o, style = "rmarkdown", caption =  "Validity effect(invalid-valid) for salient and non salient test trials(outliers)")



# pander(t.test(data = Exp8agg_o, RT_io~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, outliers")
# # 
# # 
# pander(t.test(data = Exp8agg_o, RT_io~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for nonsalient trials, outliers")

##for outliers

Valeffectplot <- ggplot(mean_valEffect_o, aes(x=Saliency, y=Mean,fill = Saliency))+
    geom_bar(stat = "identity")+
  scale_fill_manual(values = c("cadetblue3","deepskyblue4"))+
  theme_classic()+ylab("Validity effect (invalid - valid trials) in ms")+ggtitle("Difference between invalid and valid trials")
Valeffectplot

#ggsave(filename = here("Figures","Valeffectplot_o.png"),Valeffectplot,width = 6, height = 4)

```

## 4. Error Rate

> Error Rate data show a huge significant main effect of Saliency $F = 18.5, p < .001$ and a large significant interaction of validity and Saliency, $F = 14.7, p < .001$

```{r Errorate, message=FALSE, warning=FALSE,results='asis'}

##aggregate file for Error Rate with Validity and Saliency
Exp8agg_ER <- aggregate(data = Exp8data,ErrorRate~participant+Validity+Saliency,subset = (Condition == "SingleD"),mean)

##ANOVA
anova_t_ER <- ezANOVA(data = Exp8agg_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials", split.table = "Inf", missing = NA)

# anova_out(anova_t_ER)

errorrateplot <-  ggplot(Exp8agg_ER, aes(x=Saliency, y=ErrorRate,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(0,0.15))+
  theme_classic()+ylab("Error Rate")+ggtitle("Interaction of Validity and Saliency with ErrorRate as DV")
errorrateplot
#ggsave(filename = here("Figures","ErrorRate.png"),errorrateplot,width=6,height = 4)

```

The plot also shows the expected pattern, wherein the salient SingleD trials show a larger difference in valid and invalid trials' performances compared to the nonsalient SingleD trials.

**Since the results are absent in RT but present in ER,it becomes interesting to investigate this effect using a combined score**

## 5. Inverse Efficiency scores and Balance Integration Score

1.  The Inverse Efficiency score ([Bruyer, R & Brysbaert, M., 2011](https://www.psychologicabelgica.com/articles/abstract/10.5334/pb-51-1-5/)) simply combines the RT and Error Rate into a single variable, $IES = RT/(1-ErrorRate)$

2.  The Balance Integration Score (Liesefeld & Jancyzk, 2019) is another form of combining RT and Error Rate but in contrast to the IES, the BIS standardizes the two variables and computes a single variable using this formula, $BIS = z(1-ErrorRate) - z(RT)$

This [research article](https://link.springer.com/article/10.3758/s13428-018-1076-x#Bib1) talks about these methods in depth

```{r faroutsies, include=FALSE}
## create a df that contains both Errorrate and RT

Exp8test <- Exp8data %>%
  subset(Condition == "SingleD")
```

Outliers

1.  **with IES as Dependent variable**

> There is a significant interaction with validity and saliency and a main effect of saliency with a marginal significance for validity $F = 3.18, p = .07$

The ANOVA results along with the interaction plot are shown below. The mean difference graph is also presented to have a different visualization of the effects.

```{r outliersiesbis, echo = FALSE, warning=FALSE, message=FALSE,results='asis'}

###FOR OUTLIERS

Exp8agg_IES_o <- aggregate(Exp8test[,c("RT_io","ErrorRate","ACC_trials")], by = list(participant = Exp8test$participant,
                                                                       Validity = Exp8test$Validity,
                                                                       Saliency = Exp8test$Saliency), mean,na.rm = TRUE)

Exp8agg_IES_o$IES <- Exp8agg_IES_o$RT_io/(1-Exp8agg_IES_o$ErrorRate)
Exp8agg_IES_o$ZRT <- scale(Exp8agg_IES_o$RT_io)
Exp8agg_IES_o$ZPC <- scale(Exp8agg_IES_o$ACC_trials)
Exp8agg_IES_o$BIS <- Exp8agg_IES_o$ZPC - Exp8agg_IES_o$ZRT

##with IES
anova_t_IES_o <- ezANOVA(data = Exp8agg_IES_o,
        dv = IES,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_IES_o, style = 'rmarkdown', caption = "ANOVA results: using IES(outliers)", split.table = "Inf", missing = NA)

IESinterplot_o <- ggplot(Exp8agg_IES_o, aes(x=Saliency, y=IES,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(550,700))+
  theme_classic()+ylab("IES (in ms)")+ggtitle("Interaction of Validity and Saliency")
IESinterplot_o
#ggsave(filename = here("Figures","IESinterplot_o.png"),IESinterplot_o)

```


The plot below shows the mean difference in validity across saliency. Although in this case, both salient and nonsalient trials show a significant validity effect with salient ones having a larger effect

```{r IESplot, warning=FALSE, message=FALSE}
meanIES_o <- ezStats(data = Exp8agg_IES_o,
        dv = IES,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff = .(Validity),
        reverse_diff = TRUE)

# pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, outliers")
# # # 
# # # 
# pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for nonsalient trials, outliers")

pander(meanIES_o, style = "rmarkdown", caption = "Mean IES score validity effect")

valeffectIES_o <- ggplot(data = meanIES_o, aes(x = Saliency, y = Mean, fill = Saliency))+scale_fill_manual(values = c("cadetblue3","deepskyblue4"))+
  geom_bar(stat = "identity")+
  theme_classic()+
  ylab("Validity Effect(invalid-valid trials) in ms")+theme(legend.title = element_blank())+
  ggtitle("Validity Effect (invalid - valid) across test trials (IES) averaged across participant")
valeffectIES_o
#ggsave(filename = here("Figures","valEffectwithIES_o.png"),valeffectIES_o)


```

2.  **with BIS as dependent variable**

> There is a significant saliency effect and a significant interaction between validity and saliency. Validity effect is still not significant.

The ANOVA and the interaction plot are shown below. *To be noted in the plot: The y axis is represented as a z score*. Higher the score --> better the performance.

```{r BIS, echo=FALSE, warning=FALSE, message=FALSE, results='asis'}
##with BIS
anova_t_BIS_o <- ezANOVA(data = Exp8agg_IES_o,
        dv = BIS,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_BIS_o, style = 'rmarkdown', caption = "ANOVA results: using BIS(outliers)", split.table = "Inf", missing = NA)


BISinterplot_o <- ggplot(Exp8agg_IES_o, aes(x=Saliency, y=BIS,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("BIS (z score difference)")+ggtitle("Interaction of Validity and Saliency")
BISinterplot_o
#ggsave(filename = here("Figures","BISinterplot_o.png"),BISinterplot_o)


```

The mean difference is also significant for IES and BIS in the salient condition *but also in the nonsalient* condition however it is reversed in the non salient condition.

1.  **IES**

```{r iesmean, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}

##outliers
pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

2.  **BIS**

```{r meanBIS, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}
##outliers
pander(t.test(data = Exp8agg_IES_o, BIS~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp8agg_IES_o, BIS~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

## 6. With Awareness

Here, we explore the role of insight and awareness and see if participants' ability to detect the contingencies play a role in a significant overshadowing effect. The Awareness was tested in two ways:

1.  via guessing trials that were presented at the end of the experiment, with a total of 8 in number, 4 per salient letter and 4 per nonsalient.

2.  Via a Questionnaire that was asked at the end of the experiment, after the trials. The questions are as follows.

    1. Did you have an impression that an even number appeared after a particular red letter? Press 'j' for yes and 'n' for no and 't' if you do not know. 
  
    2.  Did you have an impression that an odd number appeared after a particular red letter? Press 'j' for yes and 'n' for no and 't' if you do not know. 
  
    3. What response almost always followed a red "V"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.

    4. What response almost always followed a red "G"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.
  
    5. What response almost always followed "L"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.
  
    6. What response almost always followed "X"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.

### 1. Guessing trials

First some data preparation is done to examine the performance in the awareness guessing trials.

* Computing the accuracy total per salient(4) and nonsalient(4) conditions

* computing the total sum and mean accuracy

* marking participants who answered correctly for the salient letters in the guessing trials as a factor called **SalAware**. If 1, then they answered all salient trials accurately, if 0 then they had one or more errors

> 24 people answered all the salient distractor trials accurately

```{r CAguess, echo=FALSE, warning=FALSE, message=FALSE}
Exp8_CA <- Exp8_CA %>%
  select(-TargetResp_p.corr,-TargetResp_p.keys,-TargetResp_p.rt,-TargetResp.corr,-TargetResp.keys,-todebrief.rt,-Finalend.rt)
Exp8_CA$AwareResp.corr <- as.factor(Exp8_CA$AwareResp.corr)
Exp8_CA$AwareResp.keys <- as.character(Exp8_CA$AwareResp.keys)
Exp8_CA$Solution <- as.character(Exp8_CA$Solution)
Exp8_CA <- Exp8_CA %>%
  filter(participant %notin% c(20,70,12))
#two columns stating the total accuracy of guessing trials for salient and nonsalient
Exp8_CA$SalTotalAcc <- NA
Exp8_CA$NonSalTotalAcc <- NA

Exp8_CA <- Exp8_CA %>%
  mutate(SalTotalAcc = ifelse(Saliency == "Salient" & (CAResponse_2.corr == 1), 1, 0))

Exp8_CA <- Exp8_CA %>%
  mutate(NonSalTotalAcc = ifelse(Saliency == "NonSalient" & (CAResponse_2.corr == 1), 1, 0))


CA_Summary <- Exp8_CA %>%
  dplyr::group_by(participant,Condition,Saliency) %>%
  dplyr::summarise(TotalAcc = sum(CAResponse_2.corr, na.rm = TRUE),
                   MeanAcc = mean(CAResponse_2.corr, na.rm = TRUE),
                  SalAcc = sum(SalTotalAcc, na.rm = TRUE),
                  NonSalAcc = sum(NonSalTotalAcc, na.rm = TRUE))%>%
  drop_na(Condition)


CA_Summary$MeanAcc <- 100*CA_Summary$MeanAcc

CA_Summary <- CA_Summary %>%
  mutate(Salaware = ifelse(Saliency == "Salient"& MeanAcc == 100, 1, 0))

CA_Summary$participant <- as.factor(CA_Summary$participant)

pander(table(CA_Summary$Salaware),style = "rmarkdown", caption="People with awareness of contingencies for Salient letters (1)")

```

These plots show the overall accuracy of the participants in the guessing trials.

The plot shows that in the Guess trials most participants seemed to be scoring better for the Salient trials compared to the non salient.

```{r CA plot, echo=FALSE, message=FALSE, warning=FALSE}

CAplot <- ggplot(CA_Summary, aes(x = Saliency))+
  geom_violin(aes(x= Saliency,y=TotalAcc,fill=Saliency),alpha = 0.5)+
  geom_jitter(aes(x= Saliency, y = TotalAcc,color=Saliency))+
  stat_summary(aes(y = TotalAcc, group = Condition), fun.y=mean, geom="line", colour="black")+
#  geom_hline(aes(yintercept = mean(TotalAcc), group = Saliency))+
 scale_fill_manual(values = c("steelblue4","red4"))+scale_color_manual(values = c("steelblue4","red4"))+theme_classic()+
  ggtitle("Summary of Contingency Awareness scores \n split by Salient or non salient trial")
CAplot

pander(t.test(data = CA_Summary,TotalAcc~Saliency,paired = TRUE), style = "rmarkdown", caption = "t test for Accuracy rate between salient and nonsalient trials, outliers")
# # 

#ggsave(filename = here("Figures","GuessingAccuracy.png"),CAplot)

```


### 2. Awareness Questionnaire

Here, a summary dataframe is created only with the performances of the participants from the 6 questions mentioned above.


* The variable *SalQAcc* is created to check for which of the salient letter related questions did the participants answer accurately
  
  * The variable *TotalSalQAcc* tells what the total score of accuracy is for those salient related questions. 
  
* If participants answered both the salient letter related questions accuractely (*i.e., if TotalSalQAcc  = 2*) then *SalQAware* is created that denotes that the participants were aware at the questionnaire level.

> 30 people show awareness in terms of answering the salient questions accurately.

```{r awareprep, echo=FALSE, warning=FALSE, message=FALSE}
Exp8_CA$AwareResp.corr <- as.numeric(Exp8_CA$AwareResp.corr)

#creating a dataframe dealing with the performance of Awareness Questionnaire.
AwareQ <- aggregate(data = Exp8_CA, AwareResp.corr~participant+AwareQ_loop.thisN+AwareQ+AwareResp.keys+Solution,mean)

AwareQ$SalQAcc <- ifelse(AwareQ$AwareQ_loop.thisN == "2" & AwareQ$AwareResp.corr == 2 | AwareQ$AwareQ_loop.thisN == "3" & AwareQ$AwareResp.corr== 2,1,0)

pander(table(AwareQ$AwareQ,AwareQ$AwareResp.corr), style = "rmarkdown", title = "Question number and the number of participants answering accurately (1) or not (0)")
# table(AwareQ_Summary$Dicho)

A_Summary <- AwareQ %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(TotalSalQAcc = sum(SalQAcc, na.rm=TRUE))


A_Summary$SalQAware <- ifelse(A_Summary$TotalSalQAcc == "2" ,1,0)
pander(table(A_Summary$SalQAware), style = "rmarkdown", caption = "Number of participants with awareness(1) from the questionnaire")
```

### 3. Combining both measures of awareness: guessing trials and questions

Now, let's focus only on the Salient guessing trials as well as questions. So using median split, all the participants with more than 50% accuracy in the guessing learn trials are labelled as **"Aware"** and the others are marked as **"Notaware"**.

This is then compared with the participants' responses in the Questionnaire at the end of the experiment and checked if it matches with their guessing trials' performance.

> Using the median split criteria, 42 participants scored above chance in the guessing trials that were salient. 

```{r bothaware, echo=FALSE, message=FALSE, warning=FALSE}

#if learnguess salient is high label those participants as learnAware. To be used to check if they correlate with the AwareQ responses of those participants
CA_Summary <- CA_Summary %>%
  mutate(SalAwarenessMS = ifelse(Saliency == "Salient" & MeanAcc > 50, "Aware", "Notaware"))
pander((table(CA_Summary$SalAwarenessMS)),style = "rmarkdown")

Exp8agg_A_o <- merge(Exp8agg_o, CA_Summary, by = "participant")
Exp8agg_A_ER <- merge(Exp8agg_ER,CA_Summary, by = "participant")
Exp8agg_A_IES <- merge(Exp8agg_IES_o, CA_Summary, by = "participant")
#creating df that contains both performances
BothAware <- CA_Summary%>%filter(Saliency == "Salient")
BothAware <- merge(BothAware, A_Summary, by = "participant")

plotaware <- BothAware %>%
  select(c("participant", "TotalAcc","MeanAcc", "SalAwarenessMS","Salaware","SalQAware"))

# Exp8agg_A_o <- merge(Exp8agg_o,CA_Summary,by="participant")
```

The table below shows the performances in each of the awareness tasks (guessing trials and questionnaire)

```{r tablecomp, results='asis'}
pander(plotaware, caption = "Showing the participants' Guessing trial and awareness Questionnaire Performance", format = "html", floating.environment = "sidewaystable")

```

### Using Awareness factors to the main aggregate df and evaluating the influence of insight in the interaction of validity and saliency


To further evaluate how this awareness knowledge influences the interaction, a new factor was created *AwarenessMatch* that states the level of awareness the participant had and contains 4 factors:

1.  Complete Awareness: They scored higher than chance in the guessing trials and answered both the awareness questions related to Salient distractors accurately.

2.  Guess Awareness Not question: Show higher accuracy in guess salient trials but did not answer it accurately in the questionnaire

3.  QuestionAwareness Not guess: Answered the salient distractor questions accurately but scored below chance level in the guess trials

4.  No awareness: Did not have higher accuracy in the learn guess trials and no accuracy in the salient questions.

```{r awarefactor, echo=FALSE, message=FALSE, warning=FALSE}
##selecting pps who show both awareness in trials and questions

Exp8agg_A_o <- merge(Exp8agg_A_o,A_Summary,by = "participant")
Exp8agg_A_ER <- merge(Exp8agg_A_ER,A_Summary,by = "participant")
Exp8agg_A_IES <- merge(Exp8agg_A_IES, A_Summary, by = "participant")

Exp8agg_A_o <- Exp8agg_A_o%>%
  dplyr::rename(SalientGuessTrials = SalAwarenessMS,
                SaliencyAwareQuestion = SalQAware)
Exp8agg_A_o <- Exp8agg_A_o %>%
  mutate(AwarenessMatch = ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 1, "CompleteAwareness", 
                                 ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 0,"GuessAwareness Not Question",
                                        ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 1, "QuestionAwareness Not guess",
                                               ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 0,"NoAwareness",NA)))))

Exp8agg_A_ER <- Exp8agg_A_ER%>%
  dplyr::rename(SalientGuessTrials = SalAwarenessMS,
                SaliencyAwareQuestion = SalQAware)
Exp8agg_A_ER <- Exp8agg_A_ER %>%
  mutate(AwarenessMatch = ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 1, "CompleteAwareness", 
                                 ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 0,"GuessAwareness Not Question",
                                        ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 1, "QuestionAwareness Not guess",
                                               ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 0,"NoAwareness",NA)))))

Exp8agg_A_IES <- Exp8agg_A_IES%>%
  dplyr::rename(SalientGuessTrials = SalAwarenessMS,
                SaliencyAwareQuestion = SalQAware)
Exp8agg_A_IES <- Exp8agg_A_IES %>%
  mutate(AwarenessMatch = ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 1, "CompleteAwareness", 
                                 ifelse(SalientGuessTrials == "Aware" & SaliencyAwareQuestion == 0,"GuessAwareness Not Question",
                                        ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 1, "QuestionAwareness Not guess",
                                               ifelse(SalientGuessTrials == "Notaware" & SaliencyAwareQuestion == 0,"NoAwareness",NA)))))

```

### 4. ANOVA using AwarenessMatch as a factor


#### with RT

There is a main effect of saliency $F = 6.86, p = .01$ and a significant interaction between saliency and validity $F = 11.41, p < .001$. Interestingly there is also a significant 3-way interaction with awareness and saliency and validity $F = 10.64, p < .001$ which was absent in Experiment 7. 

```{r awareanova, echo=FALSE, warning=FALSE, message=FALSE}

anova_VSA_o <- ezANOVA(data = Exp8agg_A_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency.x,Validity),
        between = .(AwarenessMatch),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSA_o, style = 'rmarkdown', caption = "ANOVA with awareness (RT)",split.table = Inf, missing = NA)

awareInterG <- ggplot(Exp8agg_A_o, aes(x=Saliency.x, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~AwarenessMatch, labeller = label_wrap_gen(width = 10))+coord_cartesian(ylim = c(500,600))+xlab("Saliency")+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareInterG


#ggsave(filename = here("Figures","InteractionwithBothawareness_RT.png"),awareInterG)
```


The plot shows the different interaction pattern per awareness condition. When participants show complete awareness both in the questionnaire as well guessing trials then it is the perfect pattern of larger validity effect for salient compared to nonsalient.This type of pattern is also seen among participants who showed awareness during the questionnaire but not so during the guessing trials. Strangely, a reverse patternw as observed in the participants with awareness in the guessing trials.

```{r meansaware, echo=FALSE, warning=FALSE, message=FALSE}
mean_valEffectA_o <- ezStats(data = Exp8agg_A_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency.x,Validity),
        within = .(Saliency.x),
        diff=.(Validity),
        between = .(AwarenessMatch),
        reverse_diff = TRUE)

pander(mean_valEffectA_o, style = "rmarkdown", caption = "Validity Effect for salient and nonsalient distractors in all groups of awareness")

```

#### with ER

There is a large main effect of saliency and validity and all the two-way interactions of saliency and validity with awareness are significant. The three-way interaction is significant as well. 


```{r awareErr, message=FALSE, warning=FALSE}

anova_VSAer_o <- ezANOVA(data = Exp8agg_A_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency.x,Validity),
        between = .(AwarenessMatch),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSAer_o, style = "rmarkdown", caption = "ANOVA with awareness: ER",split.table = Inf, missing = NA)
```

The plot looks as expected for people with complete awareness and with people who are aware at the questionnaire level but not with guessing trials. However, in contrast to the RT data, the participants with awareness at theguessing but not the questions also show a similar, expected pattern but not as large.


```{r awareplotER, message=FALSE, warning=FALSE}
awareInterG_ER <- ggplot(Exp8agg_A_ER, aes(x=Saliency.x, y=ErrorRate,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~AwarenessMatch, labeller = label_wrap_gen(width = 10))+xlab("Saliency")+
  theme_classic()+ylab("Error Rate")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareInterG_ER

#ggsave(filename = here("Figures","InteractionwAwareness_ER.png"), awareInterG_ER)

```
### with IES

These results are similar to the one seen wit ER.

```{r awreIES, warning=FALSE, message=FALSE}
anova_VSAIES_o <- ezANOVA(data = Exp8agg_A_IES,
        dv =IES,
        wid = participant,
        within = .(Saliency.x,Validity),
        between = .(AwarenessMatch),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSAIES_o,style = "rmarkdown", caption = "ANOVA with awareness: IES",split.table = Inf, missing = NA)

awareInterG_IES <- ggplot(Exp8agg_A_IES, aes(x=Saliency.x, y=IES,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~AwarenessMatch, labeller = label_wrap_gen(width = 10))+xlab("Saliency")+
  theme_classic()+ylab("IES (in ms)")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareInterG_IES

#ggsave(filename = here("Figures","InteractionwAwareness_IES.png"), awareInterG_IES)
```


```{r ttestaware, eval=FALSE}

# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "CompleteAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with full awareness")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "GuessAwareness Not Question"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only trials)")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "QuestionAwareness Not guess"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only question)")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "NoAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with no awareness")
```



### 5. Only using awareness level at the questionnaire level

This variable (*SalQAWare*) is then included as a factor in the main aggregate df containing the validity and saliency effect for test trials. There is a significant interaction between validity and saliency similar to the standard analysis. While splitting the data for people with and without awareness, the people with awareness show a significant interaction between validity and saliency and those without awareness do not show any effect.

> So in this case, even at the RT level, people with awareness show a significance interaction with was not there in the pooled data

```{r awareanalysis, include=FALSE, warning=FALSE, message=FALSE}
# Exp8agg_A_fo <- merge(Exp8agg_fo,A_Summary,by="participant")
Exp8agg_AQ_o <- merge(Exp8agg_o,A_Summary,by="participant")

```

```{r awareanalysis0, message=FALSE, warning=FALSE, results='asis'}

##for outliers

Exp8agg_AQ_o$SalQAware <- as.factor(Exp8agg_AQ_o$SalQAware)
anova_VSAq_o <- ezANOVA(data = Exp8agg_AQ_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        between = (SalQAware),
        detailed = TRUE)

pander(anova_VSAq_o, style = 'rmarkdown', caption = "ANOVA results with awareness: Outliers excluded",split.table = "Inf", missing = NA)


awareQInter <- ggplot(Exp8agg_AQ_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~SalQAware)+coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareQInter

#ggsave(filename = here("Figures","interactionbwAwareness_Questions.png"),awareQInter)

mean_awareQ_o <- ezStats(data = Exp8agg_AQ_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        between = .(SalQAware),
        diff=.(Validity),
        reverse_diff = TRUE)

pander(mean_awareQ_o, style = "rmarkdown", title = "Validity effect(invalid-valid) (outliers excluded) for participants with contingency awareness of salient letters")

```

# MULTI LEVEL MODELLING -- 

check memo - Exp8_MLM-report.html

```{r include=FALSE}

#compute new vars####
  #compute new numeric var for validity effect
  Exp8data$val <-ifelse(Exp8data$Validity=="valid",1,-1)
  table(Exp8data$val, Exp8data$Validity)

  table(Exp8data$val, Exp8data$Condition)

  #numeric var for saliency
  Exp8data$sal<-ifelse(Exp8data$Saliency=="Salient",1,
                       ifelse(Exp8data$Saliency=="NonSalient", -1, NA))

  table(Exp8data$Saliency, Exp8data$sal)


```


## 7. Previous Occurence Analysis (Distance & Response Type)

Computing a new column that contains the last time/number of trials ago the previous occurrence occurred.

Eg., Distance = 1 means that the last time the distractor appeared was one trial ago, Distance = 5 means the last time the Distractor appeared was 5 trials ago.

The conditions used to satisfy this last occurrence are:

-   Whether last trial was test/learn (*Since the trials are intermixed*)
-   Whether the Salient **OR** Non salient Distractor appeared.
-   The last occurrence was a trial that was answered correctly

```{r prevocc, eval = FALSE, message=FALSE, warning=FALSE}

Exp8data <- Exp8data%>%select(Condition, SalD,NSalD,Saliency,Validity, everything())

###first is to find out the trials where the previous occurence wa the immediate previous one
Exp8data$Distance <- NA
Exp8data <- Exp8data%>%select(Distance,ACC_trials,everything())
Exp8data <- Exp8data%>%
  mutate(Distance = ifelse((lag(Condition,1)=="SingleD" | lag(Condition,1) == "MultipleD")&
              (lag(SalD,1)== SalD|lag(NSalD,1)==NSalD) &
                            lag(participant,1)==participant &
                            lag(ACC_trials,1)== 1, 1, Distance))

#The number of immediate previous occurences
pander(table(Exp8data$Distance), style = 'rmarkdown', caption = "Table showing the number of immediate previous occurence")

## Now to look at other distances of the last occurrence beyond the immediately preceding one
lagvalue <- 2:20

for(j in lagvalue){
  Exp8data <- Exp8data %>%
    mutate(Distance = ifelse((lag(Condition,j)=="MultipleD"|lag(Condition,j)=="SingleD") &                     (lag(SalD,j)==SalD|lag(NSalD,j)==NSalD) & lag(participant,j)==participant & lag(ACC_trials,j)== 1 & is.na(Distance)==TRUE, j, Distance))
}

pander(table(Exp8data$Distance), style = 'rmarkdown', caption = "Table showing the number of total previous occurences and how far each of them are")


##code trial type for previous distance: learn trial = 1, test trial=2
  Exp8data$Distance_type<-NA
  Exp8data <- Exp8data%>%
    mutate(Distance_type = ifelse(Distance==1 & lag(Condition,1)=="MultipleD",1,
                                  ifelse(Distance==1 &lag(Condition,1)=="SingleD", 2, Distance_type)))

  table(Exp8data$Distance_type)
  Exp8data <- Exp8data%>%
    select(Distance, Distance_type, Condition, everything())

  #code for nonimmediate distances
  for (j in lagvalue){
    Exp8data <- Exp8data%>%
      mutate(Distance_type = ifelse(Distance==j & lag(Condition,j)=="MultipleD", 1,
                                    ifelse(Distance==j &lag(Condition,j)=="SingleD", 2, Distance_type)))
    }
```



### Previous Response

Coding what the previous Response was, whether it was the same or different. This variable is defined as Response Type, which has two factors: Response Change(RC) and Response Repetition (RR)

*To be noted: This does not equate to validity* because the SRB trials can have the combination of invalid prime and invalid probe --\> Response Repetition which is confounded by Validity. So every valid probe can have both the Response Type factors based on whether the prime is valid or invalid

```{r disttype, eval=FALSE, message=FALSE, warning=FALSE}

Exp8data$ResponseRel <- NA


Exp8data <- Exp8data %>%
  mutate(ResponseRel = ifelse((lag(Condition,1)=="MultipleD" | lag(Condition,1)=="SingleD") & lag(participant,1)==participant & lag(CorrectAnswer,1)== CorrectAnswer & is.na(ResponseRel)==TRUE, "RR", ifelse((lag(Condition,1)=="MultipleD"|lag(Condition,1)=="SingleD") & lag(participant,1)==participant & lag(CorrectAnswer,1)!= CorrectAnswer & is.na(ResponseRel)==TRUE, "RC", ResponseRel)))


pander(table(Exp8data$ResponseRel),style = 'rmarkdown', caption = "Total number of RRs and RCs")

Exp8data <- Exp8data%>%select(ResponseRel, everything())

#write.csv(file = here("Data","DataforMLM.csv"),Exp8data)

```
These factors are then used for the multi level modelling analysis

# Exploratory Analyses

This exploratory analysis involves the factors of contingency awareness from the guessing trials and the awareness questionnaire responses

## 1. Block Analysis


The plot shows that after te first block the participants tend to pick up on the learning and show a pattern of larger validity effect for salient trials. But there is also a strong reversal of pattern for nonsalient trials.

```{r block, warning=FALSE, message=FALSE}

Exp8agg_B_o <- aggregate(data = Exp8data, RT_io~participant+Validity+Saliency+BlockCount, subset = (Condition == "SingleD"), mean)


#Anova with Blocks ## EZANOVA error
# anova_t_block <- ezANOVA(data = Exp8agg_B_o,
#         dv = RT_io,
#         wid = participant,
#         within = .(Saliency,Validity,BlockCount),
#         detailed = TRUE)
# panderOptions('table.split.table',300)
# pander(anova_t_block, style = 'rmarkdown', caption = "ANOVA results: with BlockCount", split.table = "Inf", missing = NA)


interBlock <- ggplot(Exp8agg_B_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~BlockCount)+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency per Block")
interBlock

#ggsave(filename = here("Figures","InteractionperBlock.png"), interBlock)

```

